T = 200;
t = (1:T)';
data = sin(0.05*t) + 0.1*randn(T,1);
figure; plot(t,data); title('Original Time Series'); xlabel('Time Step'); ylabel('Value'); grid on;

X = data(1:end-1)';   % input sequence
Y = data(2:end)';     % target sequence
X = {X}; Y = {Y};     % wrap as cell (required by trainNetwork)

N = numel(X{1});
nTrain = floor(0.8 * N);
nVal   = floor(0.1 * N);
XTrain = {X{1}(:,1:nTrain)};    YTrain = {Y{1}(:,1:nTrain)};
XVal   = {X{1}(:,nTrain+1:nTrain+nVal)}; YVal = {Y{1}(:,nTrain+1:nTrain+nVal)};
XTest  = {X{1}(:,nTrain+nVal+1:end)};   YTest  = {Y{1}(:,nTrain+nVal+1:end)};

numFeatures = 1;
numResponses = 1;
numHidden = 100;
layers = [
    sequenceInputLayer(numFeatures)
    lstmLayer(numHidden)
    fullyConnectedLayer(numResponses)
    regressionLayer
];

options = trainingOptions('adam', ...
    'MaxEpochs',200, ...
    'GradientThreshold',1, ...
    'InitialLearnRate',0.005, ...
    'MiniBatchSize',1, ...
    'Shuffle','never', ...
    'ValidationData',{XVal,YVal}, ...
    'Plots','training-progress', ...
    'Verbose',false);

net = trainNetwork(XTrain, YTrain, layers, options);
YPredVal = predict(net, XVal, 'MiniBatchSize',1);
rmseVal = sqrt(mean((YPredVal{1} - YVal{1}).^2));
fprintf('Validation RMSE: %.4f\n', rmseVal);
figure;
plot(YVal{1}, '-o', 'DisplayName','Actual'); hold on;
plot(YPredVal{1}, '-x', 'DisplayName','Predicted');
title('Validation Forecast'); xlabel('Time Step'); ylabel('Value'); legend; grid on;

YPredTest = predict(net, XTest, 'MiniBatchSize',1);
rmseTest = sqrt(mean((YPredTest{1} - YTest{1}).^2));
fprintf('Test RMSE: %.4f\n', rmseTest);
figure;
plot(YTest{1}, '-o', 'DisplayName','Actual'); hold on;
plot(YPredTest{1}, '-x', 'DisplayName','Predicted');
title('Test Forecast'); xlabel('Time Step'); ylabel('Value'); legend; grid on;
