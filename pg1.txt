
txt = lower(fileread('sample_corpus.txt'));
txt = regexprep(txt, '[^a-z\s]', '');
words = strsplit(strtrim(txt));
stop = ["the","is","and","to","with","this","as","on","for","it","i","of","a","in","be"];
words = words(~ismember(words, stop));
words = words(cellfun(@(w) length(w)>1, words));

[u,~,j] = unique(words);
cnt = accumarray(j,1);
vocab = u(cnt>=2);
map = containers.Map(vocab,1:length(vocab));
words = words(ismember(words,vocab));


win = 4; pairs = [];
for i = 1:length(words)
    for k = max(1,i-win):min(length(words),i+win)
        if k~=i, pairs(end+1,:) = [map(words{i}), map(words{k})]; end
    end
end


n = length(vocab);
X = full(ind2vec(pairs(:,1)',n));
Y = categorical(pairs(:,2)',1:n);


layers = [
    featureInputLayer(n)
    fullyConnectedLayer(100)   % embedding layer
    fullyConnectedLayer(n)
    softmaxLayer
    classificationLayer];
opts = trainingOptions('adam', ...
    'MaxEpochs',50, ...
    'MiniBatchSize',128, ...
    'Plots','training-progress', ...   
    'Verbose',true);                   
net = trainNetwork(X',Y,layers,opts);


E = net.Layers(2).Weights;
disp(E(:,map('learning'))');   % Example embedding
