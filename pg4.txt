path = fullfile(matlabroot,'toolbox','nnet','nndemos','nndatasets','DigitDataset');
imds = imageDatastore(path,'IncludeSubfolders',true,'LabelSource','foldernames');
minCount = min(countEachLabel(imds).Count);
imds = splitEachLabel(imds,minCount,'randomized');
imds = shuffle(imds);

numImages = 1000;
X = zeros(28*28,numImages);
for i = 1:numImages
    img = im2double(imresize(readimage(imds,i),[28 28]));
    X(:,i) = img(:);
end
X = single(X');     % Shape: [1000 x 784]

n = round(0.8*numImages);
XTrain = X(1:n,:); XVal = X(n+1:end,:);
YTrain = XTrain; YVal = XVal;  % Autoencoder: input = output

layers = [
    featureInputLayer(784)
    fullyConnectedLayer(128)
    reluLayer
    fullyConnectedLayer(64)
    reluLayer
    fullyConnectedLayer(32)    % bottleneck layer
    fullyConnectedLayer(64)
    reluLayer
    fullyConnectedLayer(128)
    reluLayer
    fullyConnectedLayer(784)
    regressionLayer
];

opts = trainingOptions('adam', ...
    'MaxEpochs',20, ...
    'MiniBatchSize',64, ...
    'Shuffle','every-epoch', ...
    'ValidationData',{XVal,YVal}, ...
    'Plots','training-progress', ...
    'Verbose',false);

% Step 6: Train Autoencoder
net = trainNetwork(XTrain,YTrain,layers,opts);

% Step 7: Predict Reconstruction
YTrainPred = predict(net,XTrain);
YValPred = predict(net,XVal);

% Step 8: Visualize Reconstruction
figure;
for i = 1:5
    subplot(2,5,i), imshow(reshape(XTrain(i,:),[28 28])), title('Original');
    subplot(2,5,i+5), imshow(reshape(YTrainPred(i,:),[28 28])), title('Reconstructed');
end
sgtitle('Autoencoder - Image Reconstruction');

% Step 9: Compute Mean Squared Error
mseTrain = mean((XTrain(:)-YTrainPred(:)).^2);
mseVal = mean((XVal(:)-YValPred(:)).^2);
fprintf('\nMean Squared Error:\nTrain = %.6f\nVal   = %.6f\n', mseTrain, mseVal);
